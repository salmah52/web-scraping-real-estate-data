{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Web Scraping Real Estate Data from Dynamic Website</b>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Introduction</b>\n",
    "\n",
    "Data is one of the most valuable assets a business can possess and sits at the core of data science and data analysis. Web scraping is a data acquisition technique that has become a hot topic among those with rising demands for big data. In this project, I createD a web scraper to extract data from a dynamic webpage, which is a page that displays different content for different users while retaining the same layout and design - data on the webpage can be mutable or changeable.\n",
    "\n",
    "Web scraping real estate data can be a handy tool for business owners and consumers alike. By automating the process of collecting and organizing real estate information, you can save time and effort while still getting the data you need.\n",
    "\n",
    "Web scraping is a way to collect data from websites without actually visiting them. You can use web scraping to collect information from social media sites like Facebook, Twitter, LinkedIn, and Instagram. It can also get data from government websites like census data or even blogs and news websites.This way, you can quickly and easily search for what you need quickly and easily without having to look through dozens of different websites whenever you want something new."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importation of Libraries**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load web scrapping packages\n",
    "#import selenium and time\n",
    "from selenium import webdriver\n",
    "#from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.select import Select\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "import time\n",
    "\n",
    "#initialize Firefox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#craete a csv file for the scraped data\n",
    "with open(\"Main2_estate.csv\", \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(\"Room, Location, Description, Duration, Price, Bedroom, Bathroom, Toilet, Parking, Contact \\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize Chrome\n",
    "driver =webdriver.Chrome(executable_path= r\"C:\\Users\\lasis\\OneDrive\\Desktop\\webdrivers\\chromedriver.exe\")\n",
    "#Open URL\n",
    "rent = \"https://nigeriapropertycentre.com/\"\n",
    "driver.get(rent)\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#search by rent\n",
    "rent = driver.find_element(By.XPATH,'//*[@id=\"li-cid-for-rent\"]/a/label')\n",
    "rent.click()\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#search by type\n",
    "type =  driver.find_element(By.XPATH,'//*[@id=\"tid\"]/option[2]')\n",
    "type.click()\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#search by bedroom\n",
    "bedroom =  driver.find_element(By.XPATH,'//*[@id=\"bedrooms\"]')\n",
    "bedroom.click()\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#search by price-minprice\n",
    "minprice =  driver.find_element(By.XPATH,'//*[@id=\"minprice\"]')\n",
    "minprice.click()\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#search by price-maxprice\n",
    "maxprice =  driver.find_element(By.XPATH,'//*[@id=\"maxprice\"]')\n",
    "maxprice.click()\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#search by search tag\n",
    "search =  driver.find_element(By.XPATH,'//*[@id=\"search_jsForm\"]/div[4]/div/div/div/div/div/div[2]/div/div[4]/button/span')\n",
    "search.click()\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#search by state in Lagos\n",
    "Lagos =  driver.find_element(By.XPATH,'//*[@id=\"rmjs-1\"]/li[25]/a')\n",
    "Lagos.click()\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrape data\n",
    "\n",
    "for k in range(1, 700, 1):\n",
    "    Rooms = driver.find_elements(By.XPATH, '//a/h4[@class=\"content-title\"]')\n",
    "    Locations = driver.find_elements(By.XPATH, '//div[3]/address/strong')\n",
    "    Descriptions = driver.find_elements(By.XPATH, '//div[@class=\"description hidden-xs\"]/p')\n",
    "    Durations = driver.find_elements(By.XPATH, '//span[@class=\"added-on added-recently\"] ')\n",
    "    Prices = driver.find_elements(By.XPATH, \"//span[1]/span[2]\")\n",
    "    Bedrooms = driver.find_elements(By.XPATH, \"//div/div/div[4]/ul/li[1]/span[1]\") \n",
    "    Bathrooms = driver.find_elements(By.XPATH, \"//div/div/div[4]/ul/li[2]/span[1]\")\n",
    "    Toilets = driver.find_elements(By.XPATH, \"//div/div/div[4]/ul/li[3]/span[1]\")\n",
    "    Parkings = driver.find_elements(By.XPATH, \"//div/div/div[4]/ul/li[4]/span[1]\")\n",
    "    Contacts = driver.find_elements(By.XPATH, \"//div/div/div[3]/div[3]/span[3]\")\n",
    "\n",
    "    with open(\"Main2_estate.csv\", \"a\", encoding=\"utf-8\") as file:\n",
    "        for i in range(len(Rooms)):\n",
    "            file.write(Rooms[i].text.replace(',', '') + \",\" + Locations[i].text.replace(',', '') + \",\"  \n",
    "                   + Descriptions[i].text.replace(',', '') + \",\" + (Durations[i].text.replace(',', '') if len(Durations) > i else \"\") + \",\" \n",
    "                   + Prices[i].text.replace(',', '').replace(',', '') + \",\" \n",
    "                   + (Bedrooms[i].text.replace(',', '').replace(',', '') if len(Bedrooms) > i else \"\") + \",\"\n",
    "                   + (Bathrooms[i].text.replace(',', '').replace(',', '') if len(Bathrooms) > i else \"\") + \",\"\n",
    "                   + (Toilets[i].text.replace(',', '').replace(',', '') if len(Toilets) > i else \"\") + \",\"\n",
    "                   + (Parkings[i].text.replace(',', '').replace(',', '') if len(Parkings) > i else \"\") + \",\"\n",
    "                   + (Contacts[i].text.replace('\\n', '-').replace('\\n', '-') if len(Contacts) > i else \"\") + \",\"\n",
    "                      # print(text.replace('\\n', ' - '))\n",
    "                    \"\\n\")\n",
    "    \n",
    "    # Add a small delay to allow the page to load\n",
    "    time.sleep(3)\n",
    "    \n",
    "    current_url = driver.current_url\n",
    "    print(f\"Scraping page {k}: {current_url}\")\n",
    "    \n",
    "    driver.find_element(By.LINK_TEXT,'›')\n",
    "    \n",
    "    next_buttons = driver.find_elements(By.LINK_TEXT,'›')\n",
    "    print(f\"Number of next buttons found: {len(next_buttons)}\")\n",
    "    \n",
    "    if len(next_buttons) > 0:\n",
    "        next_button = next_buttons[0]\n",
    "        next_button.click()\n",
    "    else:\n",
    "        break\n",
    "    \n",
    "#close the driver\n",
    "driver.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from selenium.webdriver.common.by import By\n",
    "# from selenium.common.exceptions import StaleElementReferenceException\n",
    "\n",
    "# try:\n",
    "#     Contacts = driver.find_elements(By.XPATH, \"//div/div/div[3]/div[3]/span[3]\")\n",
    "#     for contact in Contacts:\n",
    "#         text = contact.text\n",
    "#         print(text.replace('\\n', ' - '))\n",
    "# except StaleElementReferenceException:\n",
    "#     # If StaleElementReferenceException is raised, locate the element again\n",
    "#     Contacts = driver.find_elements(By.XPATH, \"//div/div/div[3]/div[3]/span[3]\")\n",
    "#     for contact in Contacts:\n",
    "#         text = contact.text\n",
    "#         print(text.replace('\\n', ' - '))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Rooms length:\", len(Rooms))\n",
    "# print(\"Locations length:\", len(Locations))\n",
    "# print(\"Descriptions length:\", len(Descriptions))\n",
    "# print(\"Durations length:\", len(Durations))\n",
    "# print(\"Prices length:\", len(Prices))\n",
    "# print(\"Bedrooms length:\", len(Bedrooms))\n",
    "# print(\"Bathrooms length:\", len(Bathrooms))\n",
    "# print(\"Toilets length:\", len(Toilets))\n",
    "# print(\"Parkings length:\", len(Parkings))\n",
    "# print(\"Contacts length:\", len(Contacts))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "825afde2499fda61280b7870c6384ed6a1cda501e6096b116168a7015e02550a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
